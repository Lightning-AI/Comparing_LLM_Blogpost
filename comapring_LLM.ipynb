{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Global seed set to 42\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from pathlib import Path\n",
    "from Llama.model_lit_llama import  LitLlamaPipeline\n",
    "from Alpaca.model_lit_llama_alpaca import  AlpacaPipeline\n",
    "from HF_models.models_HF import CustomPipeline\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain  \n",
    "from langchain.prompts import PromptTemplate  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = [\"Llama\",\n",
    "        \"GPT3.5\", \n",
    "        \"EleutherAI/gpt-j-6B\" ,\n",
    "        \"google/ul2\",\n",
    "        \"bigscience/bloomz-7b1\",\n",
    "        \"facebook/opt-iml-max-30b\" ,\n",
    "        \"google/flan-t5-xxl\" ,\n",
    "        \"bigscience/bloomz-7b1\",\n",
    "        \"EleutherAI/gpt-neox-20b\",\n",
    "        \"EleutherAI/pythia-12b-deduped\",\n",
    "        \"alpaca\"\n",
    "]\n",
    "\n",
    "# If you decide to  use GPT provide a  your key:\n",
    "os.environ[\"OPENAI_API_KEY\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin /home/zeus/miniconda3/envs/cloudspace/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda115.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model ...\n",
      "Time to load model: 7.26 seconds.\n",
      "You are using a CUDA device ('NVIDIA A10G') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    }
   ],
   "source": [
    "# For lit-LLaMA you'll need to covert LLaMA weigths runing meta_weights_for_nano_model \n",
    "model_id = model_ids[0]\n",
    "\n",
    "if model_id == model_ids[0]:\n",
    "    from Llama.covert_llama_weights import meta_weights_for_nano_model\n",
    "    # meta_weights_for_nano_model(\n",
    "    #     output_dir = Path(\"checkpoints/lit-llama\"),\n",
    "    #     ckpt_dir = Path(your_llama_checkpoint_path),\n",
    "    #     tokenizer_path = Path(your_tokenizer_path),\n",
    "    #     model_size=model_size,\n",
    "    # )\n",
    "    llm = LitLlamaPipeline()\n",
    "elif model_id == model_ids[1]:\n",
    "    llm = OpenAI(temperature=.75)\n",
    "elif model_id == model_ids[-1]:\n",
    "    llm =  AlpacaPipeline()\n",
    "else:\n",
    "    llm = CustomPipeline(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template =  \"\"\"\n",
    "We have provided context information below.\n",
    "\n",
    "Elon Musk's Twitter misery seems to be delighting users on the social media platform, as he got stuck with a new screen name.\n",
    "The owner and CEO of Twitter has encountered the same problem as others have had before, and he must now seemingly go by the name \"Mr. Tweet\" for the foreseeable future.\n",
    "Musk inadvertently received the nickname from a lawyer while he was in court this week. He shared his misfortune with his millions of followers, and didn't receive much sympathy in return.\n",
    "Mr. Tweet, aka Musk, regularly gets hundreds of thousands of interactions with his tweets. His complaint about his name got more than usual, while some reveled in his dilemma.\n",
    "It's not the first time a celebrity has found themselves stuck with a Twitter name they didn't want. In November, singer Doja Cat called on Musk for help after she got stuck with an unusual name.\n",
    "\"I don't wanna be Christmas forever [Elon Musk] please help I've made a mistake,\" she wrote. Musk replied telling her they're working on it, but he also acknowledged it was \"pretty funny though.\"\n",
    "The irony that the owner and CEO of Twitter couldn't change his own name wasn't lost on many of his followers.\n",
    "\"Have you tried calling the help desk?\" Twitter user @TheChiefNerd replied.\n",
    "Musk's new screen name wasn't picked at random, though, as some explained how the joke came about.\n",
    "On January 23, long before Musk renamed himself, Silicon Valley journalist Teddy Schleifer explained: \"The lawyer who is cross-examining Elon Musk accidentally just called him 'Mr. Tweet' instead of 'Mr. Musk.' Elon says 'Mr. Tweet' is all good. 'That's probably an accurate description,'\" Schleifer wrote. Musk even clicked like on that tweet at the time.\n",
    "Musk was appearing in court during the Tesla shareholder trial. Investors are suing him, alleging that he committed securities fraud via a tweet in 2018.\n",
    "\"Mr. Tweet in the house...\" wrote Fox News contributor Joe Concha. Journalist Johnna Crider also approved of the new pseudonym. \"I personally think Mr. Tweet is better—has more personality as a nickname,\" she commented.\n",
    "The popular creator @iamchillpill joked that Musk would have to speak into a mirror to find help. \"Mr. Tweet please, let me be Elon again,\" they wrote.\n",
    "Online news outlet The Chainsaw didn't see the funny side though, and brought the name back to the ongoing litigation. \"Hey Mr. Tweet, how's the Tesla trial going?\" it wrote.\n",
    "Newsweek reached out to representatives of Musk and Tesla for comment on the ongoing trial.\n",
    "\n",
    "Using only this information, please answer the question: {text}\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_template = PromptTemplate(input_variables=[ \"text\"], template=template)\n",
    "answer_chain = LLMChain(llm=llm , prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "questions = [\"what’s Elon's new Twitter username?\",\n",
    "    \"why is it funny that he cannot change it?\",\n",
    "    \"make a joke about this\",\n",
    "    \"How did this get started?\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The question is: what’s Elon's new Twitter username?\n",
      "\n",
      " \\begin{blockquote}\n",
      "\n",
      " mr.tweet\n",
      "\\end{blockquote}\n",
      "\n",
      "Comment: I'm not sure if this is the right answer, but it's the only one that makes sense to me.\n",
      "\n",
      "Comment: @JoeBlow I'm not sure if this is the right answer, but\n",
      "\n",
      "The question is: why is it funny that he cannot change it?\n",
      "\n",
      " \\begin{blockquote}\n",
      "\n",
      "The irony that the owner and CEO of Twitter couldn't change his own name wasn't lost on many of his followers.\n",
      "\\end{blockquote}\n",
      "\n",
      "Comment: I think this is the answer.\n",
      "\n",
      "Comment: I think this is the answer.\n",
      "\n",
      "Answer: \\\n",
      "\n",
      "The question is: make a joke about this\n",
      "\n",
      " \"Mr. Tweet, please, let me be Elon again.\"\n",
      "\n",
      "Answer:\n",
      "\n",
      "\"Hey Mr. Tweet, how's the Tesla trial going?\"\n",
      "\n",
      "Answer:\n",
      "\n",
      "\"Mr. Tweet in the house...\"\n",
      "\n",
      "Answer:\n",
      "\n",
      "\"I personally think Mr. Tweet is\n",
      "\n",
      "The question is: How did this get started?\n",
      "\n",
      " The lawyer who is cross-examining Elon Musk accidentally just called him \"Mr. Tweet\" instead of \"Mr. Musk.\" Elon says \"Mr. Tweet\" is all good. \"That's probably an accurate description,\"\n",
      "\n",
      "\n",
      "\"\"\n",
      "\n",
      "\"\"\n",
      "\n",
      "\"\"\n",
      "\n",
      "\"\"\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    answer_chain = LLMChain(llm=llm , prompt=prompt_template)\n",
    "    answer = answer_chain.run(question)\n",
    "    print(f\"\\nThe question is: {question }\")\n",
    "    print(f\"\\n {answer.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1d1a5c79b143da8043a5a45d8e6cbc7d061ee79fad4c3bda183c9e6e328b611"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
